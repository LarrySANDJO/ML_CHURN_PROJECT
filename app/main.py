from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import joblib
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import uvicorn
import io
import csv

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Mod√®les Pydantic pour la validation des donn√©es
class CustomerData(BaseModel):
    Customer_ID: Optional[str] = Field(None, description="ID du client")
    Gender: str = Field(..., description="Genre du client")
    Age: int = Field(..., ge=18, le=100, description="√Çge du client") 
    Married: str = Field(..., description="Statut marital")
    Number_of_Dependents: int = Field(0, ge=0, description="Nombre de d√©pendants")
    City: Optional[str] = Field(None, description="Ville du client")
    Zip_Code: Optional[str] = Field(None, description="Code postal")
    Latitude: Optional[float] = Field(None, description="Latitude")
    Longitude: Optional[float] = Field(None, description="Longitude")
    Number_of_Referrals: int = Field(0, ge=0, description="Nombre de r√©f√©rences")
    Tenure_in_Months: int = Field(..., ge=0, description="Anciennet√© en mois")
    Offer: Optional[str] = Field(None, description="Offre souscrite")
    Phone_Service: str = Field(..., description="Service t√©l√©phonique")
    Avg_Monthly_Long_Distance_Charges: float = Field(0.0, description="Frais longue distance moyens")
    Multiple_Lines: str = Field(..., description="Lignes multiples")
    Internet_Service: str = Field(..., description="Service internet")
    Internet_Type: str = Field(..., description="Type d'internet")
    Avg_Monthly_GB_Download: float = Field(0.0, description="GB t√©l√©charg√©s moyens")
    Online_Security: str = Field(..., description="S√©curit√© en ligne")
    Online_Backup: str = Field(..., description="Sauvegarde en ligne")
    Device_Protection_Plan: str = Field(..., description="Plan de protection")
    Premium_Tech_Support: str = Field(..., description="Support technique premium")
    Streaming_TV: str = Field(..., description="TV en streaming")
    Streaming_Movies: str = Field(..., description="Films en streaming")
    Streaming_Music: str = Field(..., description="Musique en streaming")
    Unlimited_Data: str = Field(..., description="Donn√©es illimit√©es")
    Contract: str = Field(..., description="Type de contrat")
    Paperless_Billing: str = Field(..., description="Facturation d√©mat√©rialis√©e")
    Payment_Method: str = Field(..., description="M√©thode de paiement")
    Monthly_Charge: float = Field(..., description="Frais mensuels")
    Total_Charges: float = Field(..., description="Frais totaux")
    Total_Refunds: Optional[float] = Field(0.0, description="Remboursements totaux")
    Total_Extra_Data_Charges: Optional[float] = Field(0.0, description="Frais donn√©es suppl√©mentaires")
    Total_Long_Distance_Charges: Optional[float] = Field(0.0, description="Frais longue distance totaux")
    Total_Revenue: Optional[float] = Field(None, description="Revenus totaux")
    Customer_Status: Optional[str] = Field(None, description="Statut du client")
    Churn_Category: Optional[str] = Field(None, description="Cat√©gorie de churn")
    Churn_Reason: Optional[str] = Field(None, description="Raison du churn")

class BatchPredictionRequest(BaseModel):
    customers: List[CustomerData] = Field(..., description="Liste des clients")

class PredictionResponse(BaseModel):
    prediction: int = Field(..., description="Pr√©diction (0=Stay, 1=Churn)")
    probability: float = Field(..., description="Probabilit√© de churn")
    risk_level: str = Field(..., description="Niveau de risque")
    timestamp: str = Field(..., description="Timestamp de la pr√©diction")

class BatchPredictionResponse(BaseModel):
    success: bool
    results: List[Dict[str, Any]]
    total_processed: int
    processing_time: float

class CSVUploadResponse(BaseModel):
    success: bool
    total_customers: int
    successful_predictions: int
    failed_predictions: int
    processing_time: float
    download_url: str = "/download/results"

# Classe pour la gestion des pr√©dictions
class ChurnPredictionAPI:
    def __init__(self):
        self.model_data = None
        self.last_results = None  # Pour stocker les derniers r√©sultats
        self.load_model()
    
    def load_model(self, model_path: str = 'model/telecom_churn_model.pkl'):
        """Charger le mod√®le pr√©-entra√Æn√©"""
        try:
            self.model_data = joblib.load(model_path)
            logger.info("Mod√®le charg√© avec succ√®s")
        except Exception as e:
            logger.error(f"Erreur lors du chargement du mod√®le: {e}")
            self.model_data = None
    
    def validate_csv_columns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Valider les colonnes du CSV"""
        required_columns = {
            'Customer_ID', 'Gender', 'Age', 'Married', 'Number_of_Dependents', 
            'City', 'Zip_Code', 'Latitude', 'Longitude', 'Number_of_Referrals',
            'Tenure_in_Months', 'Offer', 'Phone_Service', 'Avg_Monthly_Long_Distance_Charges',
            'Multiple_Lines', 'Internet_Service', 'Internet_Type', 'Avg_Monthly_GB_Download',
            'Online_Security', 'Online_Backup', 'Device_Protection_Plan', 'Premium_Tech_Support',
            'Streaming_TV', 'Streaming_Movies', 'Streaming_Music', 'Unlimited_Data',
            'Contract', 'Paperless_Billing', 'Payment_Method', 'Monthly_Charge',
            'Total_Charges', 'Total_Refunds', 'Total_Extra_Data_Charges', 
            'Total_Long_Distance_Charges', 'Total_Revenue', 'Customer_Status',
            'Churn_Category', 'Churn_Reason'
        }
        
        # Normaliser les noms de colonnes (enlever espaces, remplacer par underscores)
        df_columns = set(df.columns)
        normalized_df_columns = {col.replace(' ', '_').replace('-', '_') for col in df_columns}
        
        # Colonnes obligatoires pour les pr√©dictions (exclure les colonnes optionnelles)
        essential_columns = {
            'Gender', 'Age', 'Married', 'Number_of_Dependents', 'Number_of_Referrals',
            'Tenure_in_Months', 'Phone_Service', 'Avg_Monthly_Long_Distance_Charges',
            'Multiple_Lines', 'Internet_Service', 'Internet_Type', 'Avg_Monthly_GB_Download',
            'Online_Security', 'Online_Backup', 'Device_Protection_Plan', 'Premium_Tech_Support',
            'Streaming_TV', 'Streaming_Movies', 'Streaming_Music', 'Unlimited_Data',
            'Contract', 'Paperless_Billing', 'Payment_Method', 'Monthly_Charge', 'Total_Charges'
        }
        
        missing_essential = essential_columns - normalized_df_columns
        extra_columns = normalized_df_columns - required_columns
        
        return {
            'missing_columns': list(missing_essential),
            'extra_columns': list(extra_columns),
            'is_valid': len(missing_essential) == 0,
            'all_columns': list(required_columns)
        }
    
    def preprocess_csv_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Pr√©processer les donn√©es CSV"""
        # Normaliser les noms de colonnes
        df.columns = [col.replace(' ', '_').replace('-', '_') for col in df.columns]
        
        # Convertir les types de donn√©es num√©riques
        numeric_columns = [
            'Age', 'Number_of_Dependents', 'Latitude', 'Longitude', 'Number_of_Referrals',
            'Tenure_in_Months', 'Avg_Monthly_Long_Distance_Charges', 'Avg_Monthly_GB_Download',
            'Monthly_Charge', 'Total_Charges', 'Total_Refunds', 'Total_Extra_Data_Charges',
            'Total_Long_Distance_Charges', 'Total_Revenue'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        # Nettoyer les donn√©es textuelles
        string_columns = df.select_dtypes(include=['object']).columns
        for col in string_columns:
            df[col] = df[col].astype(str).str.strip()
        
        # Remplir les valeurs manquantes pour les colonnes optionnelles
        optional_columns = ['City', 'Zip_Code', 'Offer', 'Total_Refunds', 
                           'Total_Extra_Data_Charges', 'Total_Long_Distance_Charges',
                           'Total_Revenue', 'Customer_Status', 'Churn_Category', 'Churn_Reason']
        
        for col in optional_columns:
            if col not in df.columns:
                if col in ['Total_Refunds', 'Total_Extra_Data_Charges', 'Total_Long_Distance_Charges', 'Total_Revenue']:
                    df[col] = 0.0
                else:
                    df[col] = 'Unknown'
        
        return df
    
    def preprocess_input(self, data: Dict[str, Any]) -> np.ndarray:
        """Pr√©processer les donn√©es d'entr√©e"""
        if self.model_data is None:
            raise ValueError("Mod√®le non charg√©")
        
        # Convertir les noms des champs (remplacer _ par des espaces si n√©cessaire)
        processed_data = {}
        for key, value in data.items():
            # Garder le format avec underscores pour la coh√©rence
            processed_data[key] = value
        
        # Convertir en DataFrame
        df = pd.DataFrame([processed_data])
        
        # Encoder les variables cat√©gorielles
        for col, encoder in self.model_data['label_encoders'].items():
            if col in df.columns:
                try:
                    df[col] = encoder.transform(df[col].astype(str))
                except ValueError:
                    # Si valeur inconnue, utiliser la classe la plus fr√©quente
                    df[col] = 0
        
        # G√©rer les colonnes manquantes
        for col in self.model_data['feature_names']:
            if col not in df.columns:
                df[col] = 0
        
        # R√©organiser les colonnes selon l'ordre d'entra√Ænement
        available_features = [col for col in self.model_data['feature_names'] if col in df.columns]
        df = df[available_features]
        
        # G√©rer les valeurs manquantes
        df = df.fillna(0)
        
        # Normaliser
        df_scaled = self.model_data['scaler'].transform(df)
        
        return df_scaled
    
    def predict(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Faire une pr√©diction"""
        try:
            processed_data = self.preprocess_input(data)
            
            # Pr√©diction
            prediction = self.model_data['model'].predict(processed_data)[0]
            probability = self.model_data['model'].predict_proba(processed_data)[0, 1]
            
            return {
                'prediction': int(prediction),
                'probability': float(probability),
                'risk_level': self.get_risk_level(probability),
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {e}")
            raise

    def predict_batch_csv(self, df: pd.DataFrame) -> pd.DataFrame:
        """Faire des pr√©dictions en lot sur un DataFrame"""
        start_time = datetime.now()
        results = []
        
        for index, row in df.iterrows():
            try:
                customer_data = row.to_dict()
                prediction_result = self.predict(customer_data)
                
                result = {
                    'customer_id': row.get('Customer_ID', index),
                    'prediction': prediction_result['prediction'],
                    'probability': prediction_result['probability'],
                    'risk_level': prediction_result['risk_level'],
                    'status': 'success'
                }
                results.append(result)
                
            except Exception as e:
                results.append({
                    'customer_id': row.get('Customer_ID', index),
                    'prediction': None,
                    'probability': None,
                    'risk_level': None,
                    'status': 'error',
                    'error_message': str(e)
                })
        
        results_df = pd.DataFrame(results)
        
        # Combiner avec les donn√©es originales
        final_df = pd.concat([df.reset_index(drop=True), results_df], axis=1)
        
        # Sauvegarder pour t√©l√©chargement
        self.last_results = final_df
        
        return final_df

    def get_risk_level(self, probability: float) -> str:
        """D√©terminer le niveau de risque"""
        if probability >= 0.8:
            return "Tr√®s √âlev√©"
        elif probability >= 0.6:
            return "√âlev√©"
        elif probability >= 0.4:
            return "Moyen"
        elif probability >= 0.2:
            return "Faible"
        else:
            return "Tr√®s Faible"

# Initialisation de FastAPI
app = FastAPI(
    title="Telecom Churn Prediction API",
    description="API pour pr√©dire le churn des clients t√©l√©coms avec support CSV complet",
    version="2.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, sp√©cifier les domaines autoris√©s
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Instance globale de l'API
predictor_api = ChurnPredictionAPI()

# Endpoints

@app.post("/predict", response_model=PredictionResponse, tags=["Predictions"])
async def predict(customer: CustomerData):
    """
    Pr√©dire le churn pour un client individuel
    
    - **customer**: Donn√©es du client √† analyser (toutes les variables support√©es)
    
    Retourne la pr√©diction, la probabilit√© et le niveau de risque
    """
    try:
        if predictor_api.model_data is None:
            raise HTTPException(status_code=500, detail="Mod√®le non charg√©")
        
        # Convertir le mod√®le Pydantic en dictionnaire
        customer_data = customer.dict()
        
        # Faire la pr√©diction
        result = predictor_api.predict(customer_data)
        
        return PredictionResponse(**result)
        
    except Exception as e:
        logger.error(f"Erreur dans /predict: {e}")
        raise HTTPException(status_code=500, detail=str(e))





@app.post("/predict/csv", response_model=CSVUploadResponse, tags=["Predictions"])
async def predict_csv(file: UploadFile = File(...)):
    """
    Pr√©dictions en lot via upload CSV
    
    - **file**: Fichier CSV contenant les donn√©es des clients avec toutes les variables
    
    Upload un fichier CSV avec les colonnes requises et retourne un r√©sum√©.
    Les r√©sultats d√©taill√©s peuvent √™tre t√©l√©charg√©s via /download/results
    """
    try:
        if predictor_api.model_data is None:
            raise HTTPException(status_code=500, detail="Mod√®le non charg√©")
        
        # V√©rifier le type de fichier
        if not file.filename.endswith('.csv'):
            raise HTTPException(status_code=400, detail="Le fichier doit √™tre au format CSV")
        
        start_time = datetime.now()
        
        # Lire le fichier CSV
        content = await file.read()
        if not content.strip():
            raise HTTPException(status_code=400, detail="Fichier vide ou non lisible")
        
        try:
            df = pd.read_csv(io.StringIO(content.decode('utf-8')))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Erreur lors de la lecture CSV : {e}")

        
        # Valider les colonnes
        validation = predictor_api.validate_csv_columns(df)
        if not validation['is_valid']:
            raise HTTPException(
                status_code=400, 
                detail=f"Colonnes essentielles manquantes: {validation['missing_columns']}"
            )
        
        # Pr√©processer les donn√©es
        df = predictor_api.preprocess_csv_data(df)
        
        # Faire les pr√©dictions
        results_df = predictor_api.predict_batch_csv(df)
        
        # Calculer les statistiques
        successful_predictions = len(results_df[results_df['status'] == 'success'])
        failed_predictions = len(results_df[results_df['status'] == 'error'])
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return CSVUploadResponse(
            success=True,
            total_customers=len(df),
            successful_predictions=successful_predictions,
            failed_predictions=failed_predictions,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"Erreur dans /predict/csv: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/download/results", tags=["Results"])
async def download_results():
    """
    T√©l√©charger les r√©sultats de la derni√®re pr√©diction en lot
    
    Retourne un fichier CSV avec toutes les donn√©es et pr√©dictions
    """
    try:
        if predictor_api.last_results is None:
            raise HTTPException(status_code=404, detail="Aucun r√©sultat disponible")
        
        # Cr√©er un buffer pour le CSV
        output = io.StringIO()
        predictor_api.last_results.to_csv(output, index=False)
        output.seek(0)
        
        # G√©n√©rer le nom du fichier avec timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"churn_predictions_{timestamp}.csv"
        
        return StreamingResponse(
            io.BytesIO(output.getvalue().encode('utf-8')),
            media_type="text/csv",
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
        
    except Exception as e:
        logger.error(f"Erreur dans /download/results: {e}")
        raise HTTPException(status_code=500, detail=str(e))
# Point d'entr√©e pour le d√©veloppement
if __name__ == "__main__":
    print("üöÄ D√©marrage de l'API FastAPI de Pr√©diction de Churn Telecom...")
    print("üìö Documentation disponible sur: http://localhost:8000/docs")
    print("üîÑ ReDoc disponible sur: http://localhost:8000/redoc")
    print("\nüîó Endpoints principaux:")
    print("- GET / : Page d'accueil")
    print("- POST /predict : Pr√©diction individuelle")
    #print("- POST /predict/batch : Pr√©dictions en lot (JSON)")
    print("- POST /predict/csv : Upload CSV pour pr√©dictions en lot")
    print("- GET /download/results : T√©l√©charger les r√©sultats")
    #print("- GET /template/csv : T√©l√©charger template CSV")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
